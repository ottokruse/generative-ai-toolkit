{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ff95ba",
   "metadata": {},
   "source": [
    "# Deploying a Generative AI Toolkit agent on AWS Lambda\n",
    "\n",
    "Here's a minimal rundown of what it takes to deploy your Generative AI Toolkit agent on **AWS Lambda** and expose it as a **Function URL**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e83419",
   "metadata": {},
   "source": [
    "## Step 1: Create a DynamoDB table for conversation history and traces\n",
    "\n",
    "In order to persist conversation history and traces, we'll need a DynamoDB table. Generative AI Toolkit needs a table with partition key `pk`, sort key `sk`, and a GSI with partition key `conversation_id` and sort key `sk`.\n",
    "\n",
    "Here's how to quickly create one with the CLI:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a16365",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws dynamodb create-table \\\n",
    "  --table-name MyAgentTable \\\n",
    "  --attribute-definitions \\\n",
    "    AttributeName=pk,AttributeType=S \\\n",
    "    AttributeName=sk,AttributeType=S \\\n",
    "    AttributeName=conversation_id,AttributeType=S \\\n",
    "  --key-schema \\\n",
    "    AttributeName=pk,KeyType=HASH \\\n",
    "    AttributeName=sk,KeyType=RANGE \\\n",
    "  --billing-mode PAY_PER_REQUEST \\\n",
    "  --global-secondary-indexes '[{\"IndexName\":\"by_conversation_id\",\"KeySchema\":[{\"AttributeName\":\"conversation_id\",\"KeyType\":\"HASH\"},{\"AttributeName\":\"sk\",\"KeyType\":\"RANGE\"}],\"Projection\":{\"ProjectionType\":\"ALL\"}}]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca27270",
   "metadata": {},
   "source": [
    "Here's CDK code for the same, with two additions:\n",
    "\n",
    "1. A stream is configured on the table. You would use that for calculating metrics on your deployed agents (see other docs, we won't do that in this notebook).\n",
    "2. A `timeToLiveAttribute` is configured, so traces are automatically deleted after 30 days (configurable, doesn't apply to conversation history).\n",
    "\n",
    "```typescript\n",
    "// Create table:\n",
    "const agentTable = new cdk.aws_dynamodb.Table(this, \"MyAgentTable\", {\n",
    "    partitionKey: {\n",
    "      name: \"pk\",\n",
    "      type: cdk.aws_dynamodb.AttributeType.STRING,\n",
    "    },\n",
    "    sortKey: {\n",
    "      name: \"sk\",\n",
    "      type: cdk.aws_dynamodb.AttributeType.STRING,\n",
    "    },\n",
    "    removalPolicy: cdk.RemovalPolicy.DESTROY,\n",
    "    stream: cdk.aws_dynamodb.StreamViewType.NEW_IMAGE,\n",
    "    pointInTimeRecovery: true,\n",
    "    encryption: cdk.aws_dynamodb.TableEncryption.CUSTOMER_MANAGED,\n",
    "    billingMode: cdk.aws_dynamodb.BillingMode.PAY_PER_REQUEST,\n",
    "    timeToLiveAttribute: \"expire_at\",\n",
    "});\n",
    "// GSI:\n",
    "agentTable.addGlobalSecondaryIndex({\n",
    "    indexName: \"by_conversation_id\",\n",
    "    partitionKey: {\n",
    "      name: \"conversation_id\",\n",
    "      type: cdk.aws_dynamodb.AttributeType.STRING,\n",
    "    },\n",
    "    sortKey: {\n",
    "      name: \"sk\",\n",
    "      type: cdk.aws_dynamodb.AttributeType.STRING,\n",
    "    },\n",
    "    projectionType: cdk.aws_dynamodb.ProjectionType.ALL,\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfdff23",
   "metadata": {},
   "source": [
    "## Step 2: Create Agent and Tool\n",
    "\n",
    "A very minimal Generative AI Toolkit agent would only subclass the `BedrockConverseAgent` and e.g. set a system prompt and have one tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a10746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_ai_toolkit.agent import BedrockConverseAgent\n",
    "from generative_ai_toolkit.conversation_history import DynamoDbConversationHistory\n",
    "from generative_ai_toolkit.tracer.dynamodb import DynamoDbTracer\n",
    "\n",
    "\n",
    "class MyAgent(BedrockConverseAgent):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            model_id=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "            temperature=0.0,\n",
    "            system_prompt=\"You are a helpful assistant. Use your tools to help the user as well as you can.\",\n",
    "            conversation_history=DynamoDbConversationHistory(\n",
    "                table_name=\"MyAgentTable\"\n",
    "            ),\n",
    "            tracer=DynamoDbTracer(table_name=\"MyAgentTable\"),\n",
    "        )\n",
    "\n",
    "def get_current_weather_report(city_name: str):\n",
    "    \"\"\"\n",
    "    Gets the current weather report for a city.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    city_name : str\n",
    "        The city name, e.g. \"New York City\", \"Paris\", \"Amsterdam\"\n",
    "    \"\"\"\n",
    "\n",
    "    return f\"It's currently very sunny in {city_name}.\"\n",
    "\n",
    "my_agent = MyAgent()\n",
    "my_agent.register_tool(get_current_weather_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf1cc5",
   "metadata": {},
   "source": [
    "## Step 3: Quick local test of your agent\n",
    "\n",
    "The agent will invoke the LLM and the tool to help you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_agent.reset() # Ensure we're in a new conversation, should you execute this notebook cell multiple times ;)\n",
    "\n",
    "for tokens in my_agent.converse_stream(\"Hi there! I'm in a train to Amsterdam. Tell me what the weather is there currently.\"):\n",
    "    print(tokens, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51004a",
   "metadata": {},
   "source": [
    "See everything that happened under the hood by inspecting the traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e895b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trace in my_agent.traces:\n",
    "    print(trace.as_human_readable())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85ac69",
   "metadata": {},
   "source": [
    "There's also a Web UI to inspect the traces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_ai_toolkit.ui import traces_ui\n",
    "\n",
    "demo = traces_ui(my_agent.traces)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6c56c",
   "metadata": {},
   "source": [
    "## Step 4: Deploying to AWS Lambda\n",
    "\n",
    "In this example, we'll package our Lambda function as a Dockerfile (just a choice).\n",
    "\n",
    "### Runner\n",
    "\n",
    "We must add one thing to the agent's code to make it \"runnable\" on AWS Lambda, we need to import and configure the `Runner`:\n",
    "\n",
    "```python\n",
    "from generative_ai_toolkit.run.agent import Runner\n",
    "Runner.configure(\n",
    "    agent=MyAgent,  # Point to you agent class\n",
    ")\n",
    "```\n",
    "\n",
    "This works because the return value of `Runner()` is a WSGI application that we can run with `gunicorn`, see next.\n",
    "\n",
    "### Dockerfile\n",
    "\n",
    "Here's a Dockerfile that would work. Note that we're using the [AWS Lambda Web Adapter](https://github.com/awslabs/aws-lambda-web-adapter) to run our agent as a HTTP server inside Lambda (with WSGI). This works well for response streaming, when we expose the function with a Function URL.\n",
    "\n",
    "```Dockerfile\n",
    "####\n",
    "# Docker file\n",
    "####\n",
    "FROM public.ecr.aws/docker/library/python:3.12-slim\n",
    "\n",
    "# AWS Lambda Web Adapter\n",
    "COPY --from=public.ecr.aws/awsguru/aws-lambda-adapter:0.8.4 /lambda-adapter /opt/extensions/lambda-adapter\n",
    "\n",
    "ENV UV_COMPILE_BYTECODE=1 \\\n",
    "    UV_SYSTEM_PYTHON=1\n",
    "\n",
    "WORKDIR /var/task\n",
    "\n",
    "COPY --from=ghcr.io/astral-sh/uv:0.4.0 /uv /bin/uv\n",
    "\n",
    "RUN uv pip install \"generative_ai_toolkit[run-agent]\"\n",
    "\n",
    "# This presumes you have saved the agent code above in agent.py:\n",
    "COPY agent.py ./\n",
    "\n",
    "# Have gunicorn start the Runner that is in agent.py:\n",
    "CMD [\"gunicorn\", \"-b=:8080\", \"agent:Runner()\"]\n",
    "```\n",
    "\n",
    "### AWS CDK\n",
    "\n",
    "Here's the AWS CDK code to deploy the Lambda function and enable the Function URL:\n",
    "\n",
    "```typescript\n",
    "// Function:\n",
    "const fn = new cdk.aws_lambda.DockerImageFunction(this, \"Agent\", {\n",
    "  code: cdk.aws_lambda.DockerImageCode.fromImageAsset(\n",
    "    // Let's presume this dir is where you saved both the agent.py and the Dockerfile:\n",
    "    path.join(__dirname, \"my-agent-dir\")\n",
    "  ),\n",
    "  memorySize: 1024,\n",
    "  timeout: cdk.Duration.minutes(5),\n",
    "  environment: {\n",
    "    AWS_LWA_INVOKE_MODE: \"RESPONSE_STREAM\",\n",
    "    CONVERSATION_HISTORY_TABLE_NAME: agentTable.tableName,\n",
    "    TRACES_TABLE_NAME: agentTable.tableName,\n",
    "  },\n",
    "});\n",
    "\n",
    "// Read write permission on the DynamoDB table:\n",
    "agentTable.grantReadWriteData(fn);\n",
    "\n",
    "// Permission to invoke Bedrock LLMs\n",
    "fn.addToRolePolicy(\n",
    "  new cdk.aws_iam.PolicyStatement({\n",
    "    actions: [\n",
    "      \"bedrock:InvokeModelWithResponseStream\",\n",
    "      \"bedrock:InvokeModel\",\n",
    "    ],\n",
    "    resources: [`arn:${cdk.Aws.Partition}:bedrock:${cdk.Aws.Region}::foundation-model/anthropic.claude-3-haiku-20240307-v1:0`],\n",
    "    effect: cdk.aws_iam.Effect.ALLOW,\n",
    "  })\n",
    ");\n",
    "\n",
    "// Expose as Function URL\n",
    "const lambdaUrl = fn.addFunctionUrl({\n",
    "  authType: cdk.aws_lambda.FunctionUrlAuthType.AWS_IAM,\n",
    "  invokeMode: cdk.aws_lambda.InvokeMode.RESPONSE_STREAM,\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec897070",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c3b5911",
   "metadata": {},
   "source": [
    "## Step 5: Invoke your agent\n",
    "\n",
    "We can use curl, as it supports AWS IAM AUTH. Pass the value of `my_agent.conversation_id` in as `CONVERSATION_ID` and the agent will continue the conversation, i.e. understand that you were talking about \"Amsterdam\" earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8a187",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!curl -v \\\n",
    "  https://your-lambda-function-url \\\n",
    "  --data '{\"user_input\": \"And what are some touristic highlights of the city?\"}' \\\n",
    "  --header \"x-conversation-id: $CONVERSATION_ID\" \\\n",
    "  --header \"Content-Type: application/json\" \\\n",
    "  --header \"x-amz-security-token: $AWS_SESSION_TOKEN\" \\\n",
    "  --no-buffer \\\n",
    "  --user \"${AWS_ACCESS_KEY_ID}:${AWS_SECRET_ACCESS_KEY}\" \\\n",
    "  --aws-sigv4 \"aws:amz:$AWS_REGION:lambda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d347ad",
   "metadata": {},
   "source": [
    "The Generative AI Toolkit also includes helper code to invoke the Lambda function URL programmatically from Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2421aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generative_ai_toolkit.utils.lambda_url import IamAuthInvoker\n",
    "\n",
    "lambda_url_invoker = IamAuthInvoker(\"https://<your-lambda-function-url>\")\n",
    "response = lambda_url_invoker.converse_stream(\n",
    "    user_input=\"And what are some famous museums there?\",\n",
    "    conversation_id=my_agent.conversation_id\n",
    ")\n",
    "\n",
    "print(\"Conversation ID:\", response.conversation_id)\n",
    "print()\n",
    "for tokens in response:\n",
    "    print(tokens, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542f875",
   "metadata": {},
   "source": [
    "That's it!\n",
    "\n",
    "Happy coding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
